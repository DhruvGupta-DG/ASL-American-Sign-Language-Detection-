# ASL-American-Sign-Language-Detection-

This project helps in the creation of a human-machine interface that can improve 
communication between healthy individuals and those with hearing impairments is a crucial 
issue, aimed at replacing the need for a human translator as the third party in the 
communication. Real-Time Sign Language Interpretation allows us to implement the same 
on a device that will detect these gestures and interpret them and will give the output alphabet 
related to that gesture. Our interface will help the people to form complete sentences so that 
the other person with no knowledge of sign language can understand the expression of the 
person with hearing and speaking disorders. Further, this interface will also allow the user to 
generate a sequence of signs by entering an input sentence sequence. We are implementing this 
feature to make it more comfortable to communicate even when donâ€™t know about Sign 
language. They can simply imitate the generated sequence to convey their messages to the other 
person. The technicalities of this project are briefly explained in the methodology section.
Another extension to the project is regarding the choice of Sign language, as here we are 
focusing more on American Sign language as of now but if the time and deadlines allow us,
we will implement the same model on Indian Sign language as well. So, the user would be able 
to choose even the language on our interface and make it more user-friendly and convenient to 
use
